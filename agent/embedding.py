from langchain_openai import AzureOpenAIEmbeddings
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from dotenv import load_dotenv
import os
import sys

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
dotenv_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..",  ".env"))
print(f".env path: {dotenv_path}  exists: {os.path.exists(dotenv_path)}")
load_dotenv(dotenv_path)

# 2. Azure OpenAI ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
embedding_model = AzureOpenAIEmbeddings(
    azure_deployment=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    openai_api_type="azure",
    chunk_size=1000
)

# 3. ì„ë² ë”© ìƒì„±
def get_embedding(text: str):
    return embedding_model.embed_query(text)

# 4. Milvus ì—°ê²°
connections.connect(
    host=os.getenv("MILVUS_HOST", "localhost"),
    port=os.getenv("MILVUS_PORT", "19530")
)

# 5. Milvus ì»¬ë ‰ì…˜ ìƒì„± (ì—†ìœ¼ë©´)
def recreate_collection_if_needed(name: str, vector_dim: int):
    if name not in utility.list_collections():
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=vector_dim),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=2048)
        ]
        schema = CollectionSchema(fields, description="ì„ë² ë”© í…ŒìŠ¤íŠ¸ìš© ì»¬ë ‰ì…˜")
        collection = Collection(name=name, schema=schema)
        collection.create_index(
            field_name="embedding",
            index_params={"index_type": "IVF_FLAT", "metric_type": "COSINE", "params": {"nlist": 128}}
        )
        collection.load()
        return collection
    else:
        collection = Collection(name)
        collection.load()
        return collection


collection_name = "embedding_test"
vector = get_embedding("ì´ ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•´ì¤˜")
collection = recreate_collection_if_needed(collection_name, len(vector))

# 6. Milvusì— ë²¡í„° ì‚½ì…
def insert_text_and_embedding(text: str):
    vector = [float(x) for x in get_embedding(text)]

    insert_data = [
        {
            "embedding": vector,
            "text": text
        }
    ]
    collection.insert(insert_data)
    collection.flush()
    print(f"Milvusì— ë²¡í„° ì €ì¥ ì™„ë£Œ! (text: {text[:50]}...)")

# 7. Milvusì—ì„œ ë²¡í„° ê²€ìƒ‰
def search_similar_texts(query: str, limit: int = 3):
    query_vector = get_embedding(query)
    search_params = {"metric_type": "COSINE", 
                     "params": {"nprobe": 10}}
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=limit,
        output_fields=["text"]
    )

    return results
    # for hits in results:
    #     for hit in hits:
    #         print(f"Score: {hit.distance}, Text: {hit.entity.get('text')}")

# 8. ì„ì‹œ íŒŒì¼ì—ì„œ ì²­í‚¹ëœ í…ìŠ¤íŠ¸ ì²˜ë¦¬
def process_chunked_file(temp_file_path: str):
    """
    ì„ì‹œ íŒŒì¼ì—ì„œ ì²­í‚¹ëœ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ì„œ ì„ë² ë”©í•˜ê³  ë²¡í„°DBì— ì €ì¥í•©ë‹ˆë‹¤.
    Args:
        temp_file_path (str): ì„ì‹œ íŒŒì¼ ê²½ë¡œ
    """
    if not os.path.exists(temp_file_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {temp_file_path}")
        return
    
    print(f"ğŸ“„ ì„ì‹œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {temp_file_path}")
    
    with open(temp_file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ì²­í¬ë³„ë¡œ ë¶„ë¦¬ (--- Chunkë¡œ êµ¬ë¶„)
    chunks = content.split("--- Chunk")
    chunks = [chunk.strip() for chunk in chunks if chunk.strip()]
    
    print(f"âœ… {len(chunks)}ê°œ ì²­í¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    
    # ê° ì²­í¬ë¥¼ ì„ë² ë”©í•´ì„œ ë²¡í„°DBì— ì €ì¥
    for i, chunk in enumerate(chunks):
        # "Chunk X ---" ë¶€ë¶„ ì œê±°í•˜ê³  ì‹¤ì œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        if "---" in chunk:
            text = chunk.split("---", 1)[1].strip()
        else:
            text = chunk
        
        if text:
            print(f"ğŸ’¾ ì²­í¬ {i+1}/{len(chunks)} ì„ë² ë”© ì¤‘...")
            insert_text_and_embedding(text)
    
    print(f"ğŸ‰ ëª¨ë“  ì²­í¬ê°€ ë²¡í„°DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    try:
        os.unlink(temp_file_path)
        print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {temp_file_path}")
    except Exception as e:
        print(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

# 9. ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
def check_collection_info():
    """
    Milvus ì»¬ë ‰ì…˜ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    print("ğŸ“Š Milvus ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸")
    print("=" * 50)
    
    # ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡
    collections = utility.list_collections()
    print(f"ğŸ“‹ ì „ì²´ ì»¬ë ‰ì…˜ ê°œìˆ˜: {len(collections)}")
    for col in collections:
        print(f"  - {col}")
    
    # embedding_test ì»¬ë ‰ì…˜ ì •ë³´
    if "embedding_test" in collections:
        collection = Collection("embedding_test")
        collection.load()
        
        # ë°ì´í„° ê°œìˆ˜
        num_entities = collection.num_entities
        print(f"\nğŸ“ˆ embedding_test ì»¬ë ‰ì…˜:")
        print(f"  - ì €ì¥ëœ ë°ì´í„° ê°œìˆ˜: {num_entities}")
        
        # ìŠ¤í‚¤ë§ˆ ì •ë³´
        schema = collection.schema
        print(f"  - í•„ë“œ ê°œìˆ˜: {len(schema.fields)}")
        for field in schema.fields:
            print(f"    * {field.name}: {field.dtype}")
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (ì²˜ìŒ 3ê°œ)
        if num_entities > 0:
            print(f"\nğŸ“ ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3ê°œ):")
            results = collection.query(
                expr="id >= 0",
                output_fields=["id", "text"],
                limit=3
            )
            for i, result in enumerate(results):
                text = result['text'][:100] + "..." if len(result['text']) > 100 else result['text']
                print(f"  {i+1}. ID: {result['id']}, í…ìŠ¤íŠ¸: {text}")
    else:
        print("âŒ embedding_test ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë°›ê¸°
    if len(sys.argv) > 1:
        temp_file_path = sys.argv[1]
        process_chunked_file(temp_file_path)
    else:
        # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
        check_collection_info()
        
        # ì˜ˆì‹œ: í…ìŠ¤íŠ¸ ì‚½ì…
        # insert_text_and_embedding("ì´ ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•´ì¤˜")
        # insert_text_and_embedding("ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë¬¸ì¥ë„ ë„£ì–´ë³´ì")
        # ì˜ˆì‹œ: ê²€ìƒ‰
        # print("\n--- ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰ ê²°ê³¼ ---")
        # search_similar_texts("ë¬¸ì¥ ë²¡í„°í™” í•´ì¤˜")
