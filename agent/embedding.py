from langchain_openai import AzureOpenAIEmbeddings
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from dotenv import load_dotenv
import os
import sys
import re

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
dotenv_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "..",  ".env"))
print(f".env path: {dotenv_path}  exists: {os.path.exists(dotenv_path)}")
load_dotenv(dotenv_path)

# 2. Azure OpenAI ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
embedding_model = AzureOpenAIEmbeddings(
    azure_deployment=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    openai_api_type="azure",
    chunk_size=1000
)

# 3. ì„ë² ë”© ìƒì„±
def get_embedding(text: str):
    return embedding_model.embed_query(text)

# 4. Milvus ì—°ê²°
try:
    connections.connect(
        host=os.getenv("MILVUS_HOST", "localhost"),
        port=os.getenv("MILVUS_PORT", "19530")
    )
    print("âœ… Milvus ì—°ê²° ì„±ê³µ!")
    MILVUS_AVAILABLE = True
except Exception as e:
    print(f"âš ï¸ Milvus ì—°ê²° ì‹¤íŒ¨: {e}")
    print("Milvus ì—†ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    MILVUS_AVAILABLE = False

# 5. Milvus ì»¬ë ‰ì…˜ ìƒì„± (ì—†ìœ¼ë©´)
def recreate_collection_if_needed(name: str, vector_dim: int):
    if name not in utility.list_collections():
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=vector_dim),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=2048),
            FieldSchema(name="page", dtype=DataType.INT64),
            FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=128),
            FieldSchema(name="topic", dtype=DataType.VARCHAR, max_length=256)
        ]
        schema = CollectionSchema(fields, description="ì„ë² ë”© í…ŒìŠ¤íŠ¸ìš© ì»¬ë ‰ì…˜")
        collection = Collection(name=name, schema=schema)
        collection.create_index(
            field_name="embedding",
            index_params={"index_type": "IVF_FLAT", "metric_type": "COSINE", "params": {"nlist": 128}}
        )
        collection.load()
        return collection
    else:
        collection = Collection(name)
        collection.load()
        return collection

# LLMì„ ì´ìš©í•œ topic ì¶”ì¶œ í•¨ìˆ˜ ì˜ˆì‹œ (OpenAI)
def extract_topic(text: str) -> str:
    from langchain_openai import AzureOpenAI
    llm = AzureOpenAI(
        azure_deployment=os.getenv("DEPLOYMENT_CHAT"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
        openai_api_type="azure"
    )
    prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì£¼ì œë¥¼ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n{text[:300]}"
    return llm(prompt)

collection_name = "embedding_test"
vector = get_embedding("ì´ ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•´ì¤˜")

if MILVUS_AVAILABLE:
    collection = recreate_collection_if_needed(collection_name, len(vector))
else:
    collection = None

# 6. Milvusì— ë²¡í„° ì‚½ì…
def insert_text_and_embedding(text: str, page: int, category: str, topic: str):
    vector = [float(x) for x in get_embedding(text)]
    insert_data = [
        {
            "embedding": vector,
            "text": text,
            "page": page,
            "category": category,
            "topic": topic
        }
    ]
    collection.insert(insert_data)
    collection.flush()
    print(f"Milvusì— ë²¡í„° ì €ì¥ ì™„ë£Œ! (page: {page}, category: {category}, topic: {topic}, text: {text[:50]}...)")

# 7. Milvusì—ì„œ ë²¡í„° ê²€ìƒ‰
def search_similar_texts(query: str, limit: int = 3, similarity_threshold: float = 0.7):
    """
    ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query (str): ê²€ìƒ‰í•  ì¿¼ë¦¬
        limit (int): ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
        similarity_threshold (float): ìœ ì‚¬ë„ ì„ê³„ê°’ (0~1, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
    
    Returns:
        list: ì„ê³„ê°’ì„ ë§Œì¡±í•˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ë“¤
    """
    if not MILVUS_AVAILABLE:
        print("âš ï¸ Milvusê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    query_vector = get_embedding(query)
    search_params = {"metric_type": "COSINE", 
                     "params": {"nprobe": 10}}
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=limit,
        output_fields=["text"]
    )

    # ìœ ì‚¬ë„ ì„ê³„ê°’ í•„í„°ë§
    filtered_results = []
    for hits in results:
        for hit in hits:
            # cosine ìœ ì‚¬ë„: 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬, ì„ê³„ê°’ ì´ìƒì¸ ê²ƒë§Œ í•„í„°ë§
            if hit.distance >= similarity_threshold:
                filtered_results.append(hit)
    
    print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(results[0])}ê°œ ì¤‘ {len(filtered_results)}ê°œê°€ ì„ê³„ê°’({similarity_threshold}) ì´ìƒ")
    for hit in filtered_results:
        print(f"  - ìœ ì‚¬ë„: {hit.distance:.3f}, í…ìŠ¤íŠ¸: {hit.entity.get('text')[:50]}...")
    
    return filtered_results

# 8. ì„ì‹œ íŒŒì¼ì—ì„œ ì²­í‚¹ëœ í…ìŠ¤íŠ¸ ì²˜ë¦¬
def process_chunks(chunks: list, category: str):
    """
    (í…ìŠ¤íŠ¸, í˜ì´ì§€ë²ˆí˜¸) ë¦¬ìŠ¤íŠ¸ì™€ ì¹´í…Œê³ ë¦¬ë¥¼ ë°›ì•„ ì„ë² ë”© ë° ë²¡í„°DBì— ì €ì¥í•©ë‹ˆë‹¤.
    Args:
        chunks (list): (í…ìŠ¤íŠ¸, í˜ì´ì§€ë²ˆí˜¸) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        category (str): ìˆ˜ë™ ì…ë ¥ ì¹´í…Œê³ ë¦¬
    """
    for i, (text, page) in enumerate(chunks):
        print(f"ğŸ’¾ ì²­í¬ {i+1}/{len(chunks)} ì„ë² ë”© ì¤‘... (page: {page}, category: {category})")
        topic_llm = extract_topic(text)
        topic = f"{category} - {topic_llm}"
        insert_text_and_embedding(text, page, category, topic)
    print(f"ğŸ‰ ëª¨ë“  ì²­í¬ê°€ ë²¡í„°DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# 9. ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
def check_collection_info():
    """
    Milvus ì»¬ë ‰ì…˜ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    print("ğŸ“Š Milvus ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸")
    print("=" * 50)
    
    # ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡
    collections = utility.list_collections()
    print(f"ğŸ“‹ ì „ì²´ ì»¬ë ‰ì…˜ ê°œìˆ˜: {len(collections)}")
    for col in collections:
        print(f"  - {col}")
    
    # embedding_test ì»¬ë ‰ì…˜ ì •ë³´
    if "embedding_test" in collections:
        collection = Collection("embedding_test")
        collection.load()
        
        # ë°ì´í„° ê°œìˆ˜
        num_entities = collection.num_entities
        print(f"\nğŸ“ˆ embedding_test ì»¬ë ‰ì…˜:")
        print(f"  - ì €ì¥ëœ ë°ì´í„° ê°œìˆ˜: {num_entities}")
        
        # ìŠ¤í‚¤ë§ˆ ì •ë³´
        schema = collection.schema
        print(f"  - í•„ë“œ ê°œìˆ˜: {len(schema.fields)}")
        for field in schema.fields:
            print(f"    * {field.name}: {field.dtype}")
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (ì²˜ìŒ 3ê°œ)
        if num_entities > 0:
            print(f"\nğŸ“ ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3ê°œ):")
            results = collection.query(
                expr="id >= 0",
                output_fields=["id", "text"],
                limit=3
            )
            for i, result in enumerate(results):
                text = result['text'][:100] + "..." if len(result['text']) > 100 else result['text']
                print(f"  {i+1}. ID: {result['id']}, í…ìŠ¤íŠ¸: {text}")
    else:
        print("âŒ embedding_test ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë°›ê¸°
    if len(sys.argv) > 1:
        temp_file_path = sys.argv[1]
        process_chunked_file(temp_file_path)
    else:
        # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
        check_collection_info()
        
        # ì˜ˆì‹œ: í…ìŠ¤íŠ¸ ì‚½ì…
        # insert_text_and_embedding("ì´ ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•´ì¤˜")
        # insert_text_and_embedding("ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë¬¸ì¥ë„ ë„£ì–´ë³´ì")
        # ì˜ˆì‹œ: ê²€ìƒ‰
        # print("\n--- ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰ ê²°ê³¼ ---")
        # search_similar_texts("ë¬¸ì¥ ë²¡í„°í™” í•´ì¤˜")
