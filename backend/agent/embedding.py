import logging
import os
from langchain_openai import AzureOpenAIEmbeddings
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility



# 2. Azure OpenAI ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
embedding_model = AzureOpenAIEmbeddings(
    azure_deployment=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    openai_api_type="azure",
    chunk_size=1000
)

# 3. ì„ë² ë”© ìƒì„±
def get_embedding(text: str):
    return embedding_model.embed_query(text)

# 4. Milvus ì—°ê²°
try:
    connections.connect(
        host=os.getenv("MILVUS_HOST", "localhost"),
        port=os.getenv("MILVUS_PORT", "19530")
    )
    logging.info("embedding.py: âœ… Milvus ì—°ê²° ì„±ê³µ!")
    MILVUS_AVAILABLE = True
except Exception as e:
    logging.warning(f"embedding.py: âš ï¸ Milvus ì—°ê²° ì‹¤íŒ¨: {e}")
    logging.info("embedding.py: Milvus ì—†ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    MILVUS_AVAILABLE = False

# 5. Milvus ì»¬ë ‰ì…˜ ìƒì„± (ì—†ìœ¼ë©´)
def recreate_collection_if_needed(name: str, vector_dim: int):
    if name not in utility.list_collections():
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=vector_dim),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=2048),
            FieldSchema(name="page", dtype=DataType.INT64),
            FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=128),
            FieldSchema(name="topic", dtype=DataType.VARCHAR, max_length=256)
        ]
        schema = CollectionSchema(fields, description="ì„ë² ë”© í…ŒìŠ¤íŠ¸ìš© ì»¬ë ‰ì…˜")
        collection = Collection(name=name, schema=schema)
        
        # ì••ì¶• ì•Œê³ ë¦¬ì¦˜ ì„ íƒ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥)
        index_type = os.getenv("MILVUS_INDEX_TYPE", "IVF_FLAT")
        
        # ì¸ë±ìŠ¤ íŒŒë¼ë¯¸í„° ì„¤ì •
        if index_type == "IVF_FLAT":
            index_params = {
                "index_type": "IVF_FLAT",
                "metric_type": "COSINE",
                "params": {"nlist": int(os.getenv("MILVUS_NLIST", "128"))}
            }
        elif index_type == "IVF_SQ8":
            index_params = {
                "index_type": "IVF_SQ8",
                "metric_type": "COSINE",
                "params": {"nlist": int(os.getenv("MILVUS_NLIST", "128"))}
            }
        elif index_type == "IVF_PQ":
            index_params = {
                "index_type": "IVF_PQ",
                "metric_type": "COSINE",
                "params": {
                    "nlist": int(os.getenv("MILVUS_NLIST", "128")),
                    "m": int(os.getenv("MILVUS_PQ_M", "8")),  # ì„œë¸Œë²¡í„° ê°œìˆ˜
                    "nbits": int(os.getenv("MILVUS_PQ_NBITS", "8"))  # ë¹„íŠ¸ ìˆ˜
                }
            }
        elif index_type == "HNSW":
            index_params = {
                "index_type": "HNSW",
                "metric_type": "COSINE",
                "params": {
                    "M": int(os.getenv("MILVUS_HNSW_M", "16")),
                    "efConstruction": int(os.getenv("MILVUS_HNSW_EF_CONSTRUCTION", "200"))
                }
            }
        else:
            # ê¸°ë³¸ê°’
            index_params = {
                "index_type": "IVF_FLAT",
                "metric_type": "COSINE",
                "params": {"nlist": 128}
            }
        
        logging.info(f"embedding.py: ğŸ”§ Milvus ì¸ë±ìŠ¤ ìƒì„±: {index_type}")
        collection.create_index(field_name="embedding", index_params=index_params)
        collection.load()
        return collection
    else:
        collection = Collection(name)
        collection.load()
        return collection

# LLMì„ ì´ìš©í•œ topic ì¶”ì¶œ í•¨ìˆ˜ ì˜ˆì‹œ (OpenAI)
def extract_topic(text: str) -> str:
    from langchain_openai import AzureChatOpenAI
    from langchain_core.messages import HumanMessage # Code added by Gemini
    llm = AzureChatOpenAI( # Code added by Gemini
        azure_deployment=os.getenv("DEPLOYMENT_CHAT"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
        openai_api_type="azure"
    )
    prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì£¼ì œë¥¼ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n{text[:300]}"
    return llm.invoke([HumanMessage(content=prompt)]).content # Code added by Gemini

collection_name = "embedding_test"
vector = get_embedding("ì´ ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•´ì¤˜")

if MILVUS_AVAILABLE:
    try:
        collection = recreate_collection_if_needed(collection_name, len(vector))
        logging.info(f"embedding.py: âœ… ì»¬ë ‰ì…˜ '{collection_name}' ì¤€ë¹„ ì™„ë£Œ")
    except Exception as e:
        logging.error(f"embedding.py: âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
        collection = None
else:
    collection = None

# 6. Milvusì— ë²¡í„° ì‚½ì…
def insert_text_and_embedding(text: str, page: int, category: str, topic: str):
    if collection is None:
        logging.error("embedding.py: âŒ ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    try:
        vector = [float(x) for x in get_embedding(text)]
        insert_data = [
            {
                "embedding": vector,
                "text": text,
                "page": page,
                "category": category,
                "topic": topic
            }
        ]
        collection.insert(insert_data)
        collection.flush()
        logging.info(f"embedding.py: Milvusì— ë²¡í„° ì €ì¥ ì™„ë£Œ! (page: {page}, category: {category}, topic: {topic}, text: {text[:50]}...)")
    except Exception as e:
        logging.error(f"embedding.py: âŒ ë²¡í„° ì‚½ì… ì‹¤íŒ¨: {e}")
        raise

# 7. Milvusì—ì„œ ë²¡í„° ê²€ìƒ‰
def search_similar_texts(query: str, limit: int = 3, similarity_threshold: float = 0.7):
    """
    ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query (str): ê²€ìƒ‰í•  ì¿¼ë¦¬
        limit (int): ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
        similarity_threshold (float): ìœ ì‚¬ë„ ì„ê³„ê°’ (0~1, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
    
    Returns:
        list: ì„ê³„ê°’ì„ ë§Œì¡±í•˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ë“¤
    """
    if not MILVUS_AVAILABLE:
        logging.warning("embedding.py: âš ï¸ Milvusê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    query_vector = get_embedding(query)
    search_params = {"metric_type": "COSINE", 
                     "params": {"nprobe": 10}}
    results = collection.search(
        data=[query_vector],
        anns_field="embedding",
        param=search_params,
        limit=limit,
        output_fields=["text"]
    )

    # ìœ ì‚¬ë„ ì„ê³„ê°’ í•„í„°ë§
    filtered_results = []
    for hits in results:
        for hit in hits:
            # cosine ìœ ì‚¬ë„: 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬, ì„ê³„ê°’ ì´ìƒì¸ ê²ƒë§Œ í•„í„°ë§
            if hit.distance >= similarity_threshold:
                filtered_results.append(hit)
    
    logging.info(f"embedding.py: ğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(results[0])}ê°œ ì¤‘ {len(filtered_results)}ê°œê°€ ì„ê³„ê°’({similarity_threshold}) ì´ìƒ")
    for hit in filtered_results:
        logging.info(f"embedding.py:   - ìœ ì‚¬ë„: {hit.distance:.3f}, í…ìŠ¤íŠ¸: {hit.entity.get('text')[:50]}...")
    
    return filtered_results

# 8. ì„ì‹œ íŒŒì¼ì—ì„œ ì²­í‚¹ëœ í…ìŠ¤íŠ¸ ì²˜ë¦¬
def process_chunks(chunks: list, category: str = ""):
    """
    (í…ìŠ¤íŠ¸, í˜ì´ì§€ë²ˆí˜¸) ë¦¬ìŠ¤íŠ¸ì™€ ì¹´í…Œê³ ë¦¬ë¥¼ ë°›ì•„ ì„ë² ë”© ë° ë²¡í„°DBì— ì €ì¥í•©ë‹ˆë‹¤.
    Args:
        chunks (list): (í…ìŠ¤íŠ¸, í˜ì´ì§€ë²ˆí˜¸) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        category (str): ìˆ˜ë™ ì…ë ¥ ì¹´í…Œê³ ë¦¬ (ì„ íƒ ì‚¬í•­)
    """
    for i, (text, page) in enumerate(chunks):
        logging.info(f"embedding.py: ğŸ’¾ ì²­í¬ {i+1}/{len(chunks)} ì„ë² ë”© ì¤‘... (page: {page}, category: {category})")
        topic_llm = extract_topic(text)
        # ì¹´í…Œê³ ë¦¬ê°€ ìˆìœ¼ë©´ í† í”½ì— í¬í•¨, ì—†ìœ¼ë©´ LLMì´ ì¶”ì¶œí•œ í† í”½ë§Œ ì‚¬ìš©
        topic = f"{category} - {topic_llm}" if category else topic_llm
        insert_text_and_embedding(text, page, category, topic)
    logging.info(f"embedding.py: ğŸ‰ ëª¨ë“  ì²­í¬ê°€ ë²¡í„°DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

# 8-1. í…Œì´ë¸” ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•œ ì²­í¬ ì²˜ë¦¬ (ê°œì„ ëœ ë²„ì „)
def process_chunks_with_metadata(chunks: list):
    """
    (í…ìŠ¤íŠ¸, í˜ì´ì§€ë²ˆí˜¸, ì¹´í…Œê³ ë¦¬, í† í”½, í…Œì´ë¸”ë©”íƒ€ë°ì´í„°) ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì„ë² ë”© ë° ë²¡í„°DBì— ì €ì¥í•©ë‹ˆë‹¤.
    Args:
        chunks (list): (í…ìŠ¤íŠ¸, í˜ì´ì§€ë²ˆí˜¸, ì¹´í…Œê³ ë¦¬, í† í”½, í…Œì´ë¸”ë©”íƒ€ë°ì´í„°) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    """
    table_count = 0
    text_count = 0
    
    for i, chunk_data in enumerate(chunks):
        try:
            if len(chunk_data) == 5:
                text, page, category, topic, table_metadata = chunk_data
            else:
                # ê¸°ì¡´ í˜•ì‹ í˜¸í™˜ì„± ìœ ì§€
                text, page = chunk_data[:2]
                category = chunk_data[2] if len(chunk_data) > 2 else ""
                topic = chunk_data[3] if len(chunk_data) > 3 else ""
                table_metadata = chunk_data[4] if len(chunk_data) > 4 else None
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ê²€ì¦
            if not text or len(text.strip()) == 0:
                logging.warning(f"embedding.py: âš ï¸ ë¹ˆ í…ìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸° (ì²­í¬ {i+1})")
                continue
            
            logging.info(f"embedding.py: ğŸ’¾ ì²­í¬ {i+1}/{len(chunks)} ì„ë² ë”© ì¤‘... (page: {page}, category: {category}, topic: {topic[:50]}...)")
            
            # í…Œì´ë¸” ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì •ë³´ ë¡œê¹…
            if table_metadata:
                table_count += 1
                logging.info(f"embedding.py: ğŸ“Š í…Œì´ë¸” ì •ë³´ - í–‰: {table_metadata.get('rows', 'N/A')}, ì—´: {table_metadata.get('columns', 'N/A')}, í‚¤: {table_metadata.get('key', 'N/A')}")
                
                # ë³‘í•©ëœ í…Œì´ë¸” ì •ë³´
                if table_metadata.get('merged_indices'):
                    logging.info(f"embedding.py: ğŸ”— ë³‘í•©ëœ í…Œì´ë¸” - ë³‘í•©ëœ ì¸ë±ìŠ¤: {table_metadata.get('merged_indices')}")
            else:
                text_count += 1
            
            insert_text_and_embedding(text, page, category, topic)
            
        except Exception as e:
            logging.error(f"embedding.py: âŒ ì²­í¬ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue
    
    logging.info(f"embedding.py: ğŸ‰ ëª¨ë“  ì²­í¬ê°€ ë²¡í„°DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    logging.info(f"embedding.py: ğŸ“ˆ í†µê³„ - í…Œì´ë¸”: {table_count}ê°œ, ì¼ë°˜ í…ìŠ¤íŠ¸: {text_count}ê°œ, ì´: {len(chunks)}ê°œ")

# 9. ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
def check_collection_info():
    """
    Milvus ì»¬ë ‰ì…˜ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    logging.info("embedding.py: ğŸ“Š Milvus ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸")
    logging.info("embedding.py: =" * 50)
    
    # ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡
    collections = utility.list_collections()
    logging.info(f"embedding.py: ğŸ“‹ ì „ì²´ ì»¬ë ‰ì…˜ ê°œìˆ˜: {len(collections)}")
    for col in collections:
        logging.info(f"embedding.py:   - {col}")
    
    # embedding_test ì»¬ë ‰ì…˜ ì •ë³´
    if "embedding_test" in collections:
        collection = Collection("embedding_test")
        collection.load()
        
        # ë°ì´í„° ê°œìˆ˜
        num_entities = collection.num_entities
        logging.info(f"embedding.py: \nğŸ“ˆ embedding_test ì»¬ë ‰ì…˜:")
        logging.info(f"embedding.py:   - ì €ì¥ëœ ë°ì´í„° ê°œìˆ˜: {num_entities}")
        
        # ìŠ¤í‚¤ë§ˆ ì •ë³´
        schema = collection.schema
        logging.info(f"embedding.py:   - í•„ë“œ ê°œìˆ˜: {len(schema.fields)}")
        for field in schema.fields:
            logging.info(f"embedding.py:     * {field.name}: {field.dtype}")
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (ì²˜ìŒ 3ê°œ)
        if num_entities > 0:
            logging.info(f"embedding.py: \nğŸ“ ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3ê°œ):")
            results = collection.query(
                expr="id >= 0",
                output_fields=["id", "text"],
                limit=3
            )
            for i, result in enumerate(results):
                text = result['text'][:100] + "..." if len(result['text']) > 100 else result['text']
                logging.info(f"embedding.py:   {i+1}. ID: {result['id']}, í…ìŠ¤íŠ¸: {text}")
    else:
        logging.info("embedding.py: âŒ embedding_test ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë°›ê¸°
    if len(sys.argv) > 1:
        temp_file_path = sys.argv[1]
        process_chunked_file(temp_file_path)
    else:
        # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
        check_collection_info()
        
        # ì˜ˆì‹œ: í…ìŠ¤íŠ¸ ì‚½ì…
        # insert_text_and_embedding("ì´ ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•´ì¤˜")
        # insert_text_and_embedding("ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë¬¸ì¥ë„ ë„£ì–´ë³´ì")
        # ì˜ˆì‹œ: ê²€ìƒ‰
        # print("\n--- ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰ ê²°ê³¼ ---")
        # search_similar_texts("ë¬¸ì¥ ë²¡í„°í™” í•´ì¤˜")
