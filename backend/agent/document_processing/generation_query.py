# ì—¬ê¸°ì„œ ì‘ì—… ì§„í–‰í•¨!! 07.08.
from datetime import datetime
from ast import literal_eval
from dotenv import load_dotenv

import requests
import os
import pandas as pd
import yaml
import json



load_dotenv()
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), ".."))

# ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±
def generate_questions_from_documents(definitions: str, flows: str, project_id: str) -> dict:

    try:
        print("ğŸš€ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± ì‹œì‘...")
        
        # 1. Azure ì„¤ì • ì´ˆê¸°í™”
        print(f"âš™ï¸ Azure ì„¤ì • ì´ˆê¸°í™” ì¤‘... (í”„ë¡œì íŠ¸: {project_id})")
        initialize_azure_config(project_id)


        # 3. í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±
        print("ğŸ¤– Azure OpenAIë¡œ ì§ˆë¬¸ ìƒì„± ì¤‘...")
        questions = create_synthesis_questions(definitions, flows)

        if not questions:
            raise ValueError("ì§ˆë¬¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¹ˆ ê²°ê³¼ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.")

        print(f"âœ… {len(questions)}ê°œì˜ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ")

        # 4. ì§ˆë¬¸ì„ Excel íŒŒì¼ë¡œ ì €ì¥
        print("ğŸ’¾ Excel íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")
        result = save_questions_to_excel(questions)
        
        if not result:
            raise ValueError("íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        print("ğŸ‰ ì§ˆë¬¸ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        return result

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"An error occurred in generate_questions_from_documents: {e}", exc_info=True)
        return None

# --- Azure OpenAI ë° DI í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ---
def get_azure_config(project_id):

    if project_id == "Public":
        config = {
            "key": os.getenv("Public_AZURE_OPENAI_KEY"),
            "endpoint": os.getenv("Public_AZURE_OPENAI_ENDPOINT"),
            "deployment": os.getenv("Public_DEPLOYMENT_CHAT"),
            "api_version": os.getenv("Public_AZURE_OPENAI_API_VERSION")
        }
    elif project_id == "Corporate":
        config = {
            "key": os.getenv("Corporate_AZURE_OPENAI_KEY"),
            "endpoint": os.getenv("Corporate_AZURE_OPENAI_ENDPOINT"),
            "deployment": os.getenv("Corporate_DEPLOYMENT_CHAT"),
            "api_version": os.getenv("Corporate_AZURE_OPENAI_API_VERSION")
        }
    elif project_id == "CLT":
        config = {
            "key": os.getenv("AZURE_OPENAI_API_KEY"),
            "endpoint": os.getenv("AZURE_OPENAI_ENDPOINT"),
            "deployment": os.getenv("DEPLOYMENT_CHAT"),
            "api_version": os.getenv("AZURE_OPENAI_API_VERSION")
        }
    else:
        raise ValueError(f"Invalid project_id: {project_id}. Use 'Public', 'Corporate', or 'CLT'")
    
    if not all(config.values()):
        raise ValueError(f"Azure config values for project_id '{project_id}' are not fully set in .env file.")
        
    return config

def initialize_azure_config(project_id):
    """ì „ì—­ Azure ì„¤ì •ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global azure_config
    azure_config = get_azure_config(project_id)
    print(f"Azure config initialized for project_id: {project_id}")


# Azure OpenAIë¥¼ í˜¸ì¶œ > ì‘ë‹µ
def get_completion_from_messages(messages, temperature=0.5):

    payload = {
        "temperature": temperature,
        "messages": messages
    }
    r = requests.post(
        f"{azure_config['endpoint']}/openai/deployments/{azure_config['deployment']}/chat/completions",
        json=payload,
        headers={'Content-Type': 'application/json', 'api-key': azure_config["key"]},
        params={'api-version': azure_config["api_version"]}
    )
    r.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
    response_json = r.json()
    return response_json['choices'][0]['message']['content']


def create_synthesis_questions(definitions: str, flows: str) -> list:

    # YAMLì—ì„œ í…œí”Œë¦¿ ë¬¸ìì—´ ë¶ˆëŸ¬ì˜¤ê¸°
    def load_prompt_template(yaml_path: str) -> str:
        with open(yaml_path, 'r', encoding='utf-8') as f:
            yaml_data = yaml.safe_load(f)
        return yaml_data['prompt_template']
    
    prompt_raw = load_prompt_template(f"{BASE_DIR}/function/prompt/generate_question_prompt.yaml")
    prompt_template = prompt_raw.format(definitions=definitions, flows=flows)

    messages = [{'role': 'user', 'content': prompt_template}]
    
    raw_response = get_completion_from_messages(messages)
    
    try:
        # ì‘ë‹µì—ì„œ ```jsonê³¼ ``` ì œê±°
        cleaned_response = raw_response.strip()
        if cleaned_response.startswith('```json'):
            cleaned_response = cleaned_response[7:].strip()
        if cleaned_response.endswith('```'):
            cleaned_response = cleaned_response[:-3].strip()
        
        # JSON íŒŒì‹±
        question_list = json.loads(cleaned_response)
        
        if isinstance(question_list, list) and len(question_list) > 0:
            return question_list
        else:
            print("LLM response was not a valid list. Returning raw response as a single-item list.")
            return [cleaned_response]
    except (ValueError, json.JSONDecodeError) as e:
        print(f"Failed to parse LLM response into a list: {raw_response}. Error: {e}")
        return [raw_response]


# ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥
def save_questions_to_excel(questions: list) -> dict:
    try:
        # questionsê°€ ë¦¬ìŠ¤íŠ¸ì´ê³  ê° í•­ëª©ì´ dictì¸ì§€ í™•ì¸
        if not isinstance(questions, list) or not all(isinstance(q, dict) for q in questions):
            print("Questions is not a list of dictionaries. Saving raw data.")
            df = pd.DataFrame({"Generated_Questions": questions})
        else:
            # í•„ë“œë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ DataFrame ìƒì„±
            df = pd.DataFrame(questions, columns=["Question", "Answer", "type", "reference"])
        
        directory_path = f'{BASE_DIR}/result/final_result'
        os.makedirs(directory_path, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        file_name = f'generate_query_list_{timestamp}.xlsx'
        full_path = os.path.join(directory_path, file_name)

        df.to_excel(full_path, index=False)
        print(f"Successfully saved questions to {full_path}")

        return {'file_name': file_name}
    except Exception as e:
        print(f"Error in save_questions_to_excel: {e}")
        return None

